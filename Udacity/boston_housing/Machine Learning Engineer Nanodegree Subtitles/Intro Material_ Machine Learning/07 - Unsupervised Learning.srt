0:00:00.090,0:00:02.420
What about unsupervised learning?

0:00:02.420,0:00:04.939
>> Right, so unsupervised learning[br]we don't get those examples.

0:00:04.939,0:00:07.750
We have just essentially[br]something like input, and

0:00:07.750,0:00:11.720
we have to derive some structure[br]from them just by looking at

0:00:11.720,0:00:13.595
the relationship between[br]the inputs themselves.

0:00:13.595,0:00:17.669
>> Right so give me an example of that.

0:00:17.669,0:00:18.280
>> So.

0:00:21.060,0:00:25.445
When you're studying different kinds[br]of animals, say, even as a kid.

0:00:25.445,0:00:27.540
>> Mm-hm.[br]>> You might start to say, oh,

0:00:27.540,0:00:29.310
there's these animals that[br]all look kind of the same.

0:00:29.310,0:00:30.270
They're all four-legged.

0:00:30.270,0:00:32.020
I'm going to call all of them dogs.

0:00:32.020,0:00:34.050
Even if they happen to be horses,[br]or cows, or whatever.

0:00:34.050,0:00:36.410
But I have developed,[br]without anyone telling me,

0:00:36.410,0:00:39.030
this sort of notion that all[br]these belong in the same class.

0:00:39.030,0:00:40.339
And it's different[br]from things like trees.

0:00:41.340,0:00:42.700
Which don't have four legs.

0:00:42.700,0:00:46.340
>> Well some do, but I mean, they have,[br]they both bark, is all I'm saying.

0:00:47.900,0:00:48.990
>> Did I really set you up for that?

0:00:48.990,0:00:49.870
>> Not on purpose.

0:00:49.870,0:00:51.880
>> I, I'm sorry, I want to apologize[br]to each and every one of you for that.

0:00:51.880,0:00:53.180
But that was pretty good.

0:00:53.180,0:00:54.580
Michael is very good at word play.

0:00:54.580,0:00:56.670
Which I guess is often[br]unsupervised as well.

0:00:57.690,0:00:58.871
No, I get a lot of [LAUGH].

0:00:58.871,0:01:01.060
>> [LAUGH] You certainly[br]get a lot of feedback.

0:01:01.060,0:01:01.640
>> Yeah, that's right.

0:01:01.640,0:01:03.520
So I say, please stop doing that.

0:01:03.520,0:01:06.960
>> So if supervised learning is[br]about function approximation,

0:01:06.960,0:01:09.540
then unsupervised learning[br]is about description.

0:01:09.540,0:01:11.360
It's about taking a set of data and

0:01:11.360,0:01:14.160
figuring out how you might divide[br]it up in one way or the other.

0:01:14.160,0:01:16.470
>> Or maybe even summarization[br]it's not just the description but

0:01:16.470,0:01:17.430
it's a shorter description.

0:01:17.430,0:01:18.970
>> Yeah, it's usually concise.

0:01:18.970,0:01:20.510
Compression.

0:01:20.510,0:01:21.850
>> Compact description.

0:01:21.850,0:01:25.355
So I might take a bunch of pixels[br]like I have here it might say, male.

0:01:25.355,0:01:26.810
>> [LAUGH] Wait, wait, wait, wait.

0:01:26.810,0:01:27.590
I'm pixels now?

0:01:28.760,0:01:29.570
>> As far as we can tell.

0:01:29.570,0:01:30.620
>> That's fine.

0:01:30.620,0:01:31.560
>> I however, am not pixels.

0:01:31.560,0:01:32.440
I know I'm not pixels.

0:01:32.440,0:01:33.560
I'm pretty sure the rest[br]of you are pixels.

0:01:33.560,0:01:34.770
>> That's right.[br]>> So I have a bunch of pixels, and

0:01:34.770,0:01:36.252
I might say male.

0:01:36.252,0:01:37.750
And or I might say female.

0:01:37.750,0:01:38.970
Or I might say dog.

0:01:38.970,0:01:40.160
Or I might say tree.

0:01:40.160,0:01:43.030
But, the point is I don't have a bunch[br]of labels that say dog, tree, male,

0:01:43.030,0:01:43.550
or female.

0:01:43.550,0:01:47.790
I just decide that pixels like[br]this belong with pixels like this.

0:01:47.790,0:01:50.980
As opposed to pixels like something[br]else that I'm pointing to behind me.

0:01:50.980,0:01:53.880
>> Yeah we're living in a world right[br]now that is devoid of any other objects.

0:01:53.880,0:01:54.660
Oh, chairs!

0:01:54.660,0:01:55.400
>> Chairs![br]Right.

0:01:55.400,0:01:58.940
So these pixels are very different[br]than those pixels because of

0:01:58.940,0:02:00.870
where they are relative[br]to the other pixels.

0:02:00.870,0:02:02.170
Say, right?

0:02:02.170,0:02:02.960
So, if you were looking-

0:02:02.960,0:02:05.250
>> I'm not sure that's helping me[br]understand unsupervised learning.

0:02:05.250,0:02:06.190
>> Go out and, go outside and

0:02:06.190,0:02:10.190
look at a crowd of people and try to[br]decide how you might divide them up.

0:02:10.190,0:02:11.830
Maybe you'll divide[br]them up by ethnicity.

0:02:11.830,0:02:15.840
Maybe you'll divide them up by[br]whether they have purposefully shaven

0:02:15.840,0:02:19.560
their hair in order to mock the bald or[br]whether they have curly hair.

0:02:19.560,0:02:21.880
Maybe you'll divide them[br]up by whether they have

0:02:23.010,0:02:24.540
goatees,[br]>> Facial hair.

0:02:24.540,0:02:25.492
>> Or whether they have grey hair,

0:02:25.492,0:02:27.020
there's lots of things that[br]you might do in order,.

0:02:27.020,0:02:28.560
>> Did you just point at me and[br]say grey hair?

0:02:28.560,0:02:30.300
>> I was pointing and[br]your head happened to be there.

0:02:30.300,0:02:30.970
>> Oh come on.[br]>> Pixels,

0:02:30.970,0:02:31.510
>> Where's the grey hair?

0:02:31.510,0:02:35.361
>> It's a two dimensional, right there,[br]it's right where your spit curl is.

0:02:36.440,0:02:37.120
All right.

0:02:37.120,0:02:38.640
>> Okay.[br]So, imagine you're dividing the world

0:02:38.640,0:02:39.390
up that way.

0:02:39.390,0:02:40.710
You could divide it up male, female.

0:02:40.710,0:02:43.486
You could divide it up short, tall,[br]wears hats, doesn't wear hats,

0:02:43.486,0:02:44.980
all kinds of ways you can divide it up.

0:02:44.980,0:02:47.750
And no one's telling you the right way[br]to divide it up, at least not directly.

0:02:47.750,0:02:48.690
That's unsupervised learning.

0:02:48.690,0:02:50.100
That's description, because now-

0:02:50.100,0:02:52.635
>> Mm.[br]>> Rather than having to send pixels of

0:02:52.635,0:02:56.786
everyone, or having to do a complete[br]description of this crowd,

0:02:56.786,0:03:00.264
you can say there were 57 males and[br]23 females say.

0:03:00.264,0:03:02.888
Or there are mostly people with beards.

0:03:02.888,0:03:04.071
>> So on.[br]>> Or whatever.

0:03:04.071,0:03:05.105
>> I like summarization for that.

0:03:05.105,0:03:05.651
That seems good.

0:03:05.651,0:03:06.233
>> I like summarization for that.

0:03:06.233,0:03:07.489
>> Yeah.[br]>> It's a nice concise description.

0:03:07.489,0:03:08.266
That's unsupervised learning.

0:03:08.266,0:03:09.165
>> Good.[br]Very good.

0:03:09.165,0:03:09.849
>> And practice.[br]>> And that's different from

0:03:09.849,0:03:10.410
supervised learning?

0:03:10.410,0:03:13.630
>> It's different in supervised learning[br]and it's different in a couple of ways.

0:03:13.630,0:03:16.400
One way that it's different[br]is all of those ways that we

0:03:16.400,0:03:18.600
could have just divided up the world.

0:03:18.600,0:03:21.530
In some sense are all equal either.

0:03:21.530,0:03:23.780
So I could divide up by sex or

0:03:23.780,0:03:27.660
I could divide up by height or I could[br]divide up by clothing or whatever.

0:03:27.660,0:03:31.700
And they're all equally good absent[br]some other signal later telling you

0:03:31.700,0:03:33.170
how you should be dividing up the world.

0:03:33.170,0:03:36.920
But supervised learning directly[br]tells you there's a signal.

0:03:36.920,0:03:38.925
This is what it ought to be,[br]and that's how you train.

0:03:38.925,0:03:39.550
And those are very different.

0:03:39.550,0:03:42.420
>> Now, but I could see ways that[br]unsupervised learning could be helpful

0:03:42.420,0:03:44.420
in the supervised setting, right?

0:03:44.420,0:03:47.660
So if I do get a nice description, and[br]it's the right kind of description,

0:03:47.660,0:03:50.930
it might help me map to, it may help me[br]do the function approximation better.

0:03:50.930,0:03:53.265
>> Right, so instead of taking[br]pixels that input, as input, and,

0:03:53.265,0:03:55.110
and labels like, male or female.

0:03:55.110,0:03:57.871
I could just simply take a summarization[br]of you like how much hair do

0:03:57.871,0:03:59.892
you have your relative height,[br]the weight, and

0:03:59.892,0:04:01.990
various things like that[br]that might help me do it.

0:04:01.990,0:04:02.740
That's right.[br]And by the way,

0:04:02.740,0:04:05.490
in practice this turns out to be[br]things like density estimation.

0:04:05.490,0:04:07.910
We do end up turning it into[br]statistics at the end of the day.

0:04:09.760,0:04:10.820
Often.

0:04:10.820,0:04:12.020
>> But[br]it's statistics from the beginning.

0:04:12.020,0:04:13.930
But when you say density estimation.

0:04:13.930,0:04:16.010
>> Yes.[br]>> Are you saying I'm stupid?

0:04:18.220,0:04:18.901
No.[br]>> All right so

0:04:18.901,0:04:20.670
what is density estimation?

0:04:20.670,0:04:22.040
>> Well they'll have to[br]take the class to find out.

0:04:22.040,0:04:22.660
>> I see.

0:04:22.660,0:04:23.160
>> Okay
